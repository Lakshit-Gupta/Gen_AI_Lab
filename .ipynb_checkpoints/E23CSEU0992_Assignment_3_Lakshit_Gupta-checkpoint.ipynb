{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWPta_zHg5xb",
        "outputId": "23fbe332-64ff-4bd9-9633-03242dcf81ed"
      },
      "source": [
        "# Assignment 3: Variational Autoencoder (VAE) \n",
        "**Student Name:** Lakshit Gupta  \n",
        "**Enrollment No:** E23CSEU0992  \n",
        "**Date:** January 27, 2026\n",
        "\n",
        "## Objective\n",
        "The objective of this lab is to understand and implement a Variational Autoencoder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDh_IgcfhMOR",
        "outputId": "177f5aa5-25b5-471f-b651-11ac42460662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNhh5JYvc_1z",
        "outputId": "8bdba798-3315-4b3e-ffe6-7be7313e15c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter dataset (mnist/fashion) : fashion\n",
            "Enter number of epochs : 50\n",
            "Enter batch size : 256\n",
            "Enter noise dimensions : 100\n",
            "Enter learning rate : 0.0009\n",
            "Enter save interval : 5\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "latent_dim = 20\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqEqI2fFb7-j",
        "outputId": "ee4915a0-ea81-47cc-a8a1-54d1725ea288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data', train=True, transform=transform, download=True\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data', train=False, transform=transform, download=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs0v6NmBb7-k"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.mu = nn.Linear(256, latent_dim)\n",
        "        self.log_var = nn.Linear(256, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        h = self.encoder(x)\n",
        "        mu = self.mu(h)\n",
        "        log_var = self.log_var(h)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, mu, log_var\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RADxpudab7-m"
      },
      "outputs": [],
      "source": [
        "def vae_loss(recon_x, x, mu, log_var):\n",
        "    recon_loss = nn.functional.binary_cross_entropy(\n",
        "        recon_x, x.view(-1, 28*28), reduction='sum'\n",
        "    )\n",
        "\n",
        "    kl_loss = -0.5 * torch.sum(\n",
        "        1 + log_var - mu.pow(2) - log_var.exp()\n",
        "    )\n",
        "\n",
        "    return recon_loss + kl_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se1yE9nbb7-m"
      },
      "outputs": [],
      "source": [
        "model = VAE(latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R73eCAyIb7-m"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, _ in train_loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon, mu, log_var = model(data)\n",
        "        loss = vae_loss(recon, data, mu, log_var)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvHgUIsPb7-n",
        "outputId": "38a068dd-ab04-4650-fbe1-7f2e44626366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 | D_loss: 0.71 | D_acc: 38.18% | G_loss: 0.56\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 2/50 | D_loss: 0.73 | D_acc: 32.16% | G_loss: 0.47\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 3/50 | D_loss: 0.73 | D_acc: 31.35% | G_loss: 0.40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 4/50 | D_loss: 0.74 | D_acc: 30.42% | G_loss: 0.34\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 5/50 | D_loss: 0.74 | D_acc: 29.44% | G_loss: 0.29\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 6/50 | D_loss: 0.75 | D_acc: 28.76% | G_loss: 0.26\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 7/50 | D_loss: 0.76 | D_acc: 28.54% | G_loss: 0.23\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 8/50 | D_loss: 0.77 | D_acc: 27.98% | G_loss: 0.21\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 9/50 | D_loss: 0.78 | D_acc: 27.52% | G_loss: 0.19\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 10/50 | D_loss: 0.80 | D_acc: 27.22% | G_loss: 0.17\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 11/50 | D_loss: 0.81 | D_acc: 27.18% | G_loss: 0.16\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 12/50 | D_loss: 0.82 | D_acc: 26.94% | G_loss: 0.15\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 13/50 | D_loss: 0.83 | D_acc: 26.94% | G_loss: 0.14\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 14/50 | D_loss: 0.84 | D_acc: 26.94% | G_loss: 0.13\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 15/50 | D_loss: 0.85 | D_acc: 26.97% | G_loss: 0.12\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 16/50 | D_loss: 0.86 | D_acc: 26.97% | G_loss: 0.12\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 17/50 | D_loss: 0.87 | D_acc: 26.91% | G_loss: 0.11\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 18/50 | D_loss: 0.88 | D_acc: 26.82% | G_loss: 0.10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 19/50 | D_loss: 0.90 | D_acc: 26.79% | G_loss: 0.10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 20/50 | D_loss: 0.91 | D_acc: 26.73% | G_loss: 0.09\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 21/50 | D_loss: 0.92 | D_acc: 26.69% | G_loss: 0.09\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 22/50 | D_loss: 0.93 | D_acc: 26.61% | G_loss: 0.09\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 23/50 | D_loss: 0.94 | D_acc: 26.38% | G_loss: 0.08\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 24/50 | D_loss: 0.95 | D_acc: 26.34% | G_loss: 0.08\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 25/50 | D_loss: 0.96 | D_acc: 26.33% | G_loss: 0.08\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 26/50 | D_loss: 0.98 | D_acc: 26.21% | G_loss: 0.07\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 27/50 | D_loss: 0.99 | D_acc: 26.19% | G_loss: 0.07\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 28/50 | D_loss: 1.00 | D_acc: 26.13% | G_loss: 0.07\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 29/50 | D_loss: 1.01 | D_acc: 26.05% | G_loss: 0.07\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 30/50 | D_loss: 1.02 | D_acc: 26.14% | G_loss: 0.07\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 31/50 | D_loss: 1.04 | D_acc: 26.17% | G_loss: 0.06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 32/50 | D_loss: 1.05 | D_acc: 26.13% | G_loss: 0.06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 33/50 | D_loss: 1.06 | D_acc: 26.10% | G_loss: 0.06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 34/50 | D_loss: 1.07 | D_acc: 26.15% | G_loss: 0.06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 35/50 | D_loss: 1.08 | D_acc: 26.14% | G_loss: 0.06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 36/50 | D_loss: 1.09 | D_acc: 26.07% | G_loss: 0.06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 37/50 | D_loss: 1.11 | D_acc: 26.03% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 38/50 | D_loss: 1.12 | D_acc: 26.05% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 39/50 | D_loss: 1.13 | D_acc: 26.00% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 40/50 | D_loss: 1.14 | D_acc: 25.97% | G_loss: 0.05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 41/50 | D_loss: 1.16 | D_acc: 26.01% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 42/50 | D_loss: 1.17 | D_acc: 26.02% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 43/50 | D_loss: 1.18 | D_acc: 26.01% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 44/50 | D_loss: 1.19 | D_acc: 26.04% | G_loss: 0.05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 45/50 | D_loss: 1.21 | D_acc: 26.02% | G_loss: 0.05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 46/50 | D_loss: 1.22 | D_acc: 26.06% | G_loss: 0.04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 47/50 | D_loss: 1.23 | D_acc: 26.01% | G_loss: 0.04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 48/50 | D_loss: 1.24 | D_acc: 25.99% | G_loss: 0.04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 49/50 | D_loss: 1.26 | D_acc: 25.96% | G_loss: 0.04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 50/50 | D_loss: 1.27 | D_acc: 25.97% | G_loss: 0.04\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(16, latent_dim).to(device)\n",
        "    samples = model.decoder(z).cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G27zNeNjb7-o",
        "outputId": "8e900a7b-cfdf-4571-fb2c-248edc7db1a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
          ]
        }
      ],
      "source": [
        "# Visualize generated images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(6,6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(samples[i].view(28,28), cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtk4qfQVb7-o",
        "outputId": "e15b6698-661c-435d-b5e9-a3f2eafdd1e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f935421df10>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data, _ = next(iter(test_loader))\n",
        "data = data.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    recon, _, _ = model(data)\n",
        "\n",
        "fig, axes = plt.subplots(2, 8, figsize=(12,3))\n",
        "for i in range(8):\n",
        "    axes[0, i].imshow(data[i].cpu().view(28,28), cmap='gray')\n",
        "    axes[0, i].set_title(\"Original\")\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    axes[1, i].imshow(recon[i].cpu().view(28,28), cmap='gray')\n",
        "    axes[1, i].set_title(\"Reconstructed\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsu1H6GFhWcx",
        "outputId": "90b8100c-bd79-48b3-95fb-686a4e178e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step\n",
            "Label Distribution of Generated Images:\n",
            "{np.int64(6): np.int64(6), np.int64(8): np.int64(94)}\n"
          ]
        }
      ],
      "source": [
        "plt.plot(train_losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"VAE Training Loss\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
